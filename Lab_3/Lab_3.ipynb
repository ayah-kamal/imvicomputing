{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 1. Tiny Images and NN Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "ename": "UnidentifiedImageError",
     "evalue": "cannot identify image file 'data/train/Coast/image_0283.jpg'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mUnidentifiedImageError\u001b[0m                    Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-8-a3d4657e70a2>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     46\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     47\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0m__name__\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'__main__'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 48\u001b[0;31m     \u001b[0mmain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-8-a3d4657e70a2>\u001b[0m in \u001b[0;36mmain\u001b[0;34m()\u001b[0m\n\u001b[1;32m     33\u001b[0m     \u001b[0mtrain_image_paths\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest_image_paths\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_labels\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest_labels\u001b[0m \u001b[0;34m=\u001b[0m\u001b[0;31m\\\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     34\u001b[0m         \u001b[0mget_image_paths\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mDATA_PATH\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mIMAGE_CATEGORIES\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m100\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 35\u001b[0;31m     \u001b[0mtrain_images\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mget_tiny_image_features\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_image_paths\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mthumbnail_size\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     36\u001b[0m     \u001b[0mtest_images\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mget_tiny_image_features\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtest_image_paths\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mthumbnail_size\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     37\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-8-a3d4657e70a2>\u001b[0m in \u001b[0;36mget_tiny_image_features\u001b[0;34m(image_paths, new_dims)\u001b[0m\n\u001b[1;32m     23\u001b[0m     \u001b[0mtiny_image_features\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     24\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mimage_path\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mimage_paths\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 25\u001b[0;31m         \u001b[0mimg\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mread_img\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimage_path\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmono\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     26\u001b[0m         \u001b[0mtiny_img\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mresize_img\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimg\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnew_dims\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     27\u001b[0m         \u001b[0mtiny_image_features\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtiny_img\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mflatten\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Desktop/ImVi Computing/Lab_3/utils.py\u001b[0m in \u001b[0;36mread_img\u001b[0;34m(path, mono)\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mread_img\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmono\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mmono\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 7\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mread_img_mono\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      8\u001b[0m     \u001b[0mimg\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mImage\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0masarray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Desktop/ImVi Computing/Lab_3/utils.py\u001b[0m in \u001b[0;36mread_img_mono\u001b[0;34m(path)\u001b[0m\n\u001b[1;32m     12\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mread_img_mono\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m     \u001b[0;31m# The L flag converts it to 1 channel.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 14\u001b[0;31m     \u001b[0mimg\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mImage\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconvert\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmode\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"L\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     15\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0masarray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     16\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/lib/python3/dist-packages/PIL/Image.py\u001b[0m in \u001b[0;36mopen\u001b[0;34m(fp, mode)\u001b[0m\n\u001b[1;32m   2859\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mmessage\u001b[0m \u001b[0;32min\u001b[0m \u001b[0maccept_warnings\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2860\u001b[0m         \u001b[0mwarnings\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwarn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmessage\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2861\u001b[0;31m     raise UnidentifiedImageError(\n\u001b[0m\u001b[1;32m   2862\u001b[0m         \u001b[0;34m\"cannot identify image file %r\"\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mfilename\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mfilename\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0mfp\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2863\u001b[0m     )\n",
      "\u001b[0;31mUnidentifiedImageError\u001b[0m: cannot identify image file 'data/train/Coast/image_0283.jpg'"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "\n",
    "from lab3_utils import get_image_paths\n",
    "from utils import read_img, resize_img\n",
    "from PIL import Image\n",
    "\n",
    "\n",
    "# Either extract the supplied data.zip in the Lab 3 directory\n",
    "# or alter DATA_PATH to point to where you extracted it.\n",
    "DATA_PATH = 'data'\n",
    "IMAGE_CATEGORIES = [\n",
    "    'Bedroom', 'Coast', 'Forest', 'Highway', 'Industrial',\n",
    "    'InsideCity', 'Kitchen', 'LivingRoom', 'Mountain', 'Office',\n",
    "    'OpenCountry', 'Store', 'Street', 'Suburb', 'TallBuilding'\n",
    "]\n",
    "\n",
    "\n",
    "def get_tiny_image_features(image_paths, new_dims):\n",
    "    \"\"\" Returns an array containing the resized images provided in the input.\n",
    "    \"\"\"\n",
    "    tiny_image_features = []\n",
    "    for image_path in image_paths:\n",
    "        img = read_img(image_path, mono=True)\n",
    "        tiny_img = resize_img(img, new_dims)\n",
    "        tiny_image_features.append(tiny_img.flatten())\n",
    "    return np.asarray(tiny_image_features)\n",
    "\n",
    "\n",
    "def main():\n",
    "    thumbnail_size = (16, 16)\n",
    "    train_image_paths, test_image_paths, train_labels, test_labels =\\\n",
    "        get_image_paths(DATA_PATH, IMAGE_CATEGORIES, 100)\n",
    "    train_images = get_tiny_image_features(train_image_paths, thumbnail_size)\n",
    "    test_images = get_tiny_image_features(test_image_paths, thumbnail_size)\n",
    "\n",
    "    knn = KNeighboursClassifier(n_neighbours = 1)\n",
    "    knn.fit(train_images, train_labels)\n",
    "    test_predictions = knn.predict(test_images)\n",
    "    # TODO: Predict on test set, and store it in a variable test_predictions.\n",
    "\n",
    "    accuracy = accuracy_score(test_labels, test_predictions)\n",
    "    print('Classification accuracy of baseline KNN:', accuracy)\n",
    "\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    main()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "bash: baseline.py: command not found\r\n"
     ]
    }
   ],
   "source": [
    "! baseline.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generating BOW features for training set...\n"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "module 'cv2' has no attribute 'SIFT_create'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-9-c54972276497>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     73\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     74\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Generating BOW features for training set...'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 75\u001b[0;31m     \u001b[0mtrain_images\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbag_of_words\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_image_paths\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcodebook\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     76\u001b[0m     \u001b[0mtrain_images_scaled\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mscaler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit_transform\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_images\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     77\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Train images:'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_images\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-9-c54972276497>\u001b[0m in \u001b[0;36mbag_of_words\u001b[0;34m(image_paths, codebook)\u001b[0m\n\u001b[1;32m     42\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     43\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mbag_of_words\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimage_paths\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcodebook\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 44\u001b[0;31m     \u001b[0msift\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcv\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mSIFT_create\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnfeatures\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mSIFT_MAX_FEATURES\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     45\u001b[0m     \u001b[0mcodebook_size\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcodebook\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     46\u001b[0m     \u001b[0mimage_features\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mAttributeError\u001b[0m: module 'cv2' has no attribute 'SIFT_create'"
     ]
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "import cv2 as cv\n",
    "import joblib\n",
    "import numpy as np\n",
    "from scipy.spatial.distance import cdist\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.svm import SVC\n",
    "\n",
    "from lab3_utils import get_image_paths\n",
    "from utils import read_img\n",
    "\n",
    "\n",
    "DATA_PATH = 'data'\n",
    "IMAGE_CATEGORIES = [\n",
    "    'Bedroom', 'Coast', 'Forest', 'Highway', 'Industrial',\n",
    "    'InsideCity', 'Kitchen', 'LivingRoom', 'Mountain', 'Office',\n",
    "    'OpenCountry', 'Store', 'Street', 'Suburb', 'TallBuilding'\n",
    "]\n",
    "SIFT_MAX_FEATURES = 50\n",
    "\n",
    "\n",
    "def build_codebook(image_paths, num_tokens=15):\n",
    "    #sift = cv.SIFT_create(nfeatures=SIFT_MAX_FEATURES)\n",
    "    sift = cv.SIFT_create()\n",
    "    container = []\n",
    "    for image_path in image_paths:\n",
    "        img = read_img(image_path, mono=True)\n",
    "        keypoints, descriptors = sift.detectAndCompute(img, None)\n",
    "        if descriptors is not None:\n",
    "            container.append(descriptors)\n",
    "    container = np.concatenate(container)\n",
    "    print(container.shape)\n",
    "    print('Training KMeans...')\n",
    "    kmeans = KMeans(n_clusters=num_tokens)\n",
    "    kmeans.fit(container)\n",
    "    print('Done')\n",
    "    return kmeans.cluster_centers_\n",
    "\n",
    "\n",
    "def bag_of_words(image_paths, codebook):\n",
    "    sift = cv.SIFT_create(nfeatures=SIFT_MAX_FEATURES)\n",
    "    codebook_size = codebook.shape[0]\n",
    "    image_features = []\n",
    "    for image_path in image_paths:\n",
    "        img = read_img(image_path, mono=True)\n",
    "        keypoints, descriptors = sift.detectAndCompute(img, None)\n",
    "        bow = np.zeros(codebook_size)\n",
    "        if descriptors is not None:\n",
    "            distances = cdist(descriptors, codebook)\n",
    "            for d in distances:\n",
    "                bow[np.argmin(d)] += 1\n",
    "        image_features.append(bow.reshape(1, codebook_size))\n",
    "    image_features = np.concatenate(image_features)\n",
    "    return image_features\n",
    "\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    train_image_paths, test_image_paths, train_labels, test_labels =\\\n",
    "        get_image_paths(DATA_PATH, IMAGE_CATEGORIES, 100)\n",
    "\n",
    "    if os.path.exists('codebook.joblib'):\n",
    "        codebook = joblib.load('codebook.joblib')\n",
    "    else:\n",
    "        codebook = build_codebook(train_image_paths)\n",
    "        print('Persisting codebook...')\n",
    "        joblib.dump(codebook, 'codebook.joblib')\n",
    "        print('Done')\n",
    "\n",
    "    scaler = StandardScaler()\n",
    "\n",
    "    print('Generating BOW features for training set...')\n",
    "    train_images = bag_of_words(train_image_paths, codebook)\n",
    "    train_images_scaled = scaler.fit_transform(train_images)\n",
    "    print('Train images:', train_images.shape)\n",
    "\n",
    "    print('Generating BOW features for test set...')\n",
    "    test_images = bag_of_words(test_image_paths, codebook)\n",
    "    test_images_scaled = scaler.transform(test_images)\n",
    "    print('Test images:', test_images.shape)\n",
    "\n",
    "    if os.path.exists('svm_bow.joblib'):\n",
    "        print('Loading existing linear SVM model...')\n",
    "        svm = joblib.load('svm_bow.joblib')\n",
    "    else:\n",
    "        print('Training a linear SVM...')\n",
    "        svm = SVC(gamma='scale')\n",
    "        svm.fit(train_images_scaled, train_labels)\n",
    "        joblib.dump(svm, 'svm_bow.joblib')\n",
    "    print('Done')\n",
    "\n",
    "    test_predictions = svm.predict(test_images_scaled)\n",
    "    accuracy = accuracy_score(test_labels, test_predictions)\n",
    "    print('Classification accuracy of SVM with BOW features:', accuracy)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
